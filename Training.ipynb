{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8uMHSCdLhd_",
    "outputId": "8dd338c8-b859-455d-f5fd-ef704f60a9e9"
   },
   "outputs": [],
   "source": [
    "!pip install python-chess\n",
    "!apt-get install stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6tPshXdL6SA"
   },
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l6tPshXdL6SA"
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wNSyvYkzbBev"
   },
   "outputs": [],
   "source": [
    "def random_board(max_depth=200):\n",
    "    # Randomly determine the stage of the game\n",
    "    if random.random() < 0.2:\n",
    "        max_depth = min(15, max_depth)  # Consider shallower depths for more opening positions\n",
    "    elif random.random() < 0.5:\n",
    "        max_depth = min(50, max_depth)  # Consider medium depths for mid-game positions\n",
    "\n",
    "    board = chess.Board()\n",
    "    depth = random.randrange(0, max_depth)\n",
    "\n",
    "    for _ in range(depth):\n",
    "        all_moves = list(board.legal_moves)\n",
    "        if not all_moves:  # Break if no legal moves are available\n",
    "            break\n",
    "\n",
    "        random_move = random.choice(all_moves)\n",
    "        board.push(random_move)\n",
    "\n",
    "        if board.is_game_over():\n",
    "            break\n",
    "\n",
    "    return board\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M84Sc53EZKDF"
   },
   "source": [
    "# creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "K5xL8kdEZDZq"
   },
   "outputs": [],
   "source": [
    "squares_index= {'a':0,'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7}\n",
    "def square_to_index(square):\n",
    "  letter = chess.square_name(square)\n",
    "  return 8 - int(letter[1]), squares_index[letter[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BRa-ezQJNrij"
   },
   "outputs": [],
   "source": [
    "def split_dims(board):\n",
    "  board3d=np.zeros((14,8,8),dtype=np.int8) #3d representation of board\n",
    "\n",
    "  # add pieces to board representation\n",
    "  for piece in chess.PIECE_TYPES:\n",
    "    for square in board.pieces(piece,chess.WHITE):\n",
    "      idx=np.unravel_index(square,(8,8))\n",
    "      board3d[piece-1][7-idx[0]][idx[1]]=1\n",
    "\n",
    "    for square in board.pieces(piece,chess.BLACK):\n",
    "      idx=np.unravel_index(square,(8,8))\n",
    "      board3d[piece+5][7- idx[0]][idx[1]]=1\n",
    "\n",
    "  #adding valid moves\n",
    "  aux=board.turn\n",
    "  board.turn=chess.WHITE\n",
    "  for move in board.legal_moves:\n",
    "    i,j=square_to_index(move.to_square)\n",
    "    board3d[12][i][j]=1\n",
    "  board.turn=chess.BLACK\n",
    "  for move in board.legal_moves:\n",
    "    i,j=square_to_index(move.to_square)\n",
    "    board3d[13][i][j]=1\n",
    "  board.turn=aux\n",
    "\n",
    "  return board3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8slGKAe5eCsf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0amHu75gB8m",
    "outputId": "63bdaafb-5d91-44c4-e0a7-e394bdf8894e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OUdET9P3x03_"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/dataset/dataset.npz  /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtiPCyiNntZr"
   },
   "outputs": [],
   "source": [
    "# Load the previous dataset if it exists\n",
    "try:\n",
    "    previous_data = np.load('dataset.npz', allow_pickle=True)\n",
    "    previous_inputs = previous_data['inputs']\n",
    "    previous_labels = previous_data['labels']\n",
    "except FileNotFoundError:\n",
    "    previous_inputs = np.array([])\n",
    "    previous_labels = np.array([])\n",
    "\n",
    "# Generate new data\n",
    "num_samples = 100000\n",
    "new_input_data_list = []\n",
    "new_labels_list = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    board = random_board()\n",
    "    x = split_dims(board)\n",
    "    y = stockfish(board, 10)\n",
    "    if y is None:\n",
    "        i -= 1\n",
    "        continue\n",
    "    new_input_data_list.append(x)\n",
    "    new_labels_list.append(y)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "new_input_data_array = np.array(new_input_data_list)\n",
    "new_labels_array = np.array(new_labels_list)\n",
    "\n",
    "# Concatenate new data with previous data\n",
    "combined_inputs = np.concatenate([previous_inputs, new_input_data_array], axis=0)\n",
    "combined_labels = np.concatenate([previous_labels, new_labels_array], axis=0)\n",
    "\n",
    "# Convert NumPy arrays to TensorFlow tensors\n",
    "combined_inputs_tensor = tf.convert_to_tensor(combined_inputs, dtype=tf.float32)\n",
    "combined_labels_tensor = tf.convert_to_tensor(combined_labels, dtype=tf.float32)\n",
    "\n",
    "# Save the combined dataset to an NPZ file\n",
    "np.savez('dataset.npz', inputs=combined_inputs_tensor.numpy(), labels=combined_labels_tensor.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CvmrozVgJju"
   },
   "outputs": [],
   "source": [
    "!cp /content/dataset.npz /content/drive/MyDrive/dataset/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEN1hQoQfbZu"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3JpS4gEJfjoX"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow.keras.optimizers as optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SHf2Z835TNDj"
   },
   "outputs": [],
   "source": [
    "from keras.activations import selu\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "def build_model(conv_size, conv_depth):\n",
    "    board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "    x = board3d\n",
    "    for _ in range(conv_depth):\n",
    "        x = layers.Conv2D(filters=32, kernel_size=(1, 1), padding='same', activation='relu', data_format='channels_first')(x)\n",
    "        x = layers.Dropout(0.25)(x)  # Apply dropout regularization in convolutional layers\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(x)  # Apply Elastic Net regularization in dense layers\n",
    "    x = layers.Dropout(0.5)(x)  # Apply dropout regularization in dense layers\n",
    "    x = layers.Dense(1, activation='selu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(x)  # Apply Elastic Net regularization in dense layers\n",
    "    #x = layers.Lambda(lambda x: x * 10)(x)\n",
    "    return models.Model(inputs=board3d, outputs=x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7rqzECS5f88r"
   },
   "outputs": [],
   "source": [
    "from keras.activations import selu\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "def build_ResNet_model(conv_size, conv_depth):\n",
    "    board3d = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu', data_format='channels_first')(board3d)\n",
    "\n",
    "    for _ in range(conv_depth):\n",
    "        previous = x\n",
    "        x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', data_format='channels_first')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Add()([x, previous])\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1, activation=selu)(x)\n",
    "    return models.Model(inputs=board3d, outputs=x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otQaR00gibFu"
   },
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9mK9Pysg3ABa"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IP3_KbVDicK_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset():\n",
    "  container=np.load('D:\\Repos\\Chess Engine\\dataset.npz', allow_pickle=True)\n",
    "  b,v=container['inputs'],container['labels']\n",
    "  v=np.asarray(v/1e4,dtype=np.float32)\n",
    "  return b,v\n",
    "\n",
    "x_train,y_train=get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQiwNpHvEQFD",
    "outputId": "3a677e85-6810-4c00-9170-848972fbd3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282977, 14, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "416Gp9XXmevh"
   },
   "outputs": [],
   "source": [
    "#model=build_model(32,4)\n",
    "model=build_ResNet_model(32,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoNhctFklUTw",
    "outputId": "45c0ef1d-0d2a-4771-8813-5c1ab7d59687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 14, 8, 8)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 8, 8)     4064        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 8, 8)     9248        ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 8, 8)    32          ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 8, 8)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 8, 8)     9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 8, 8)    32          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 32, 8, 8)     0           ['activation_10[0][0]',          \n",
      "                                                                  'conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 8, 8)     9248        ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 8, 8)    32          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 8, 8)     9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 8, 8)    32          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 32, 8, 8)     0           ['activation_12[0][0]',          \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 8, 8)     9248        ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 8, 8)    32          ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 8, 8)     9248        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 8, 8)    32          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 32, 8, 8)     0           ['activation_14[0][0]',          \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 32, 8, 8)     9248        ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 8, 8)    32          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 8, 8)     9248        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 8, 8)    32          ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 8, 8)     0           ['activation_16[0][0]',          \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 8, 8)    32          ['add_7[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 32, 8, 8)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2048)         0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2049        ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 80,385\n",
      "Trainable params: 80,241\n",
      "Non-trainable params: 144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import Huber\n",
    "\n",
    "model.compile(optimizer='adam',loss=Huber())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr-O9klm3KaP",
    "outputId": "cea0b913-fd20-4e72-f6da-04f6b721c244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.0053 - val_loss: 0.0052 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.0046 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "498/498 [==============================] - 12s 25ms/step - loss: 0.0042 - val_loss: 0.0104 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.0040 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.0039 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.0038 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.0036 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "498/498 [==============================] - 13s 25ms/step - loss: 0.0036 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "498/498 [==============================] - 13s 26ms/step - loss: 0.0035 - val_loss: 0.0032 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "498/498 [==============================] - 13s 26ms/step - loss: 0.0036 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "498/498 [==============================] - 13s 27ms/step - loss: 0.0033 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0033 - val_loss: 0.0038 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0032 - val_loss: 0.0050 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0032 - val_loss: 0.0040 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0033 - val_loss: 0.0051 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0032 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0030 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0030 - val_loss: 0.0034 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0030 - val_loss: 0.0039 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0029 - val_loss: 0.0033 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0029 - val_loss: 0.0048 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0028 - val_loss: 0.0031 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0028 - val_loss: 0.0029 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0028 - val_loss: 0.0030 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0027 - val_loss: 0.0045 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0027 - val_loss: 0.0044 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0022 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "498/498 [==============================] - 14s 29ms/step - loss: 0.0021 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0030 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0021 - val_loss: 0.0029 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 40/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 41/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 42/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 43/1000\n",
      "498/498 [==============================] - 14s 28ms/step - loss: 0.0020 - val_loss: 0.0029 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train,\n",
    "          batch_size=512,\n",
    "          epochs=1000,\n",
    "          verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss',patience=10),callbacks.EarlyStopping(monitor='val_loss',patience=15,min_delta=1e-5)]\n",
    "          )\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVbk-5WCUFsx"
   },
   "outputs": [],
   "source": [
    "!cp /content/model.h5 /content/drive/MyDrive/dataset/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5k3iwKPDsoYl"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "c2RR1IWKspHZ"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"D:\\Repos\\Chess Engine\\model.h5\", compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGrEBWhYVSqD",
    "outputId": "62d48ce0-da9c-463c-d7f6-7e90087f1e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "-165.4353365302086\n"
     ]
    }
   ],
   "source": [
    "board=random_board()\n",
    "board3d=split_dims(board)\n",
    "board3d=np.expand_dims(board3d,0)\n",
    "print(model.predict(board3d)[0][0]*1e4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 8, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=split_dims(random_board())\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NWEJVV9pK70g",
    "outputId": "5fb98e65-af2b-49e9-b434-1f06a01e0640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "input_data_list = []\n",
    "labels_list = []\n",
    "boards=[]\n",
    "temp=[]\n",
    "for i in range(num_samples):\n",
    "    board = random_board()\n",
    "    boards.append(board)\n",
    "for board in boards:\n",
    "    x = split_dims(board)\n",
    "    temp.append(x)\n",
    "\n",
    "x_input=np.array(temp)\n",
    "x_input=tf.convert_to_tensor(x_input, dtype=tf.float32)\n",
    "pred =model.predict(x_input)\n",
    "max_index = np.argmax(pred)\n",
    "temp=boards[max_index]\n",
    "#print(f'Prediction: {pred*1e4}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
